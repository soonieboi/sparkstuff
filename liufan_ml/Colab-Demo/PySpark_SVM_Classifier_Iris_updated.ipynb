{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a213b31",
      "metadata": {
        "id": "4a213b31"
      },
      "source": [
        "# This workshop demonstrate how to apply SVM classifier on multi-class classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set up spark environment and SparkSession"
      ],
      "metadata": {
        "id": "ag6sMcs-kvsO"
      },
      "id": "ag6sMcs-kvsO"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "844ff905",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "844ff905",
        "outputId": "a30b48c5-255d-4ffc-c850-3d40117f6895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package openjdk-21-jre-headless:amd64.\n",
            "(Reading database ... 126109 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-21-jre-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-21-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-21-jdk-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jwebserver to provide /usr/bin/jwebserver (jwebserver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "java-1.21.0-openjdk-amd64\n",
            "java-21-openjdk-amd64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 1. Install OpenJDK 21 (if not already done in a previous cell)\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq openjdk-21-jdk-headless\n",
        "\n",
        "# 2. Verify where it landed (if needed)\n",
        "!ls /usr/lib/jvm | grep 21\n",
        "\n",
        "# 3. Point to JDK 21\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "# 4. Install PySpark via pip (make sure this happens AFTER setting JAVA_HOME)\n",
        "!pip install pyspark --quiet\n",
        "\n",
        "# 5. Import and start Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .master(\"local[*]\")\n",
        "      .appName(\"PySpark-SVMClassifier_Iris\")\n",
        "      .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount google drive"
      ],
      "metadata": {
        "id": "zzobvvaxk4SR"
      },
      "id": "zzobvvaxk4SR"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THyKtSjaOK1Y",
        "outputId": "3f2cd1e7-37ee-4295-e3bc-d6feb900d107"
      },
      "id": "THyKtSjaOK1Y",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4078110e",
      "metadata": {
        "id": "4078110e"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ed1b26e3",
      "metadata": {
        "id": "ed1b26e3"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset into a DataFrame\n",
        "# Replace 'iris_data.csv' with the path to your dataset file\n",
        "data = spark.read.csv(\"/content/iris-data.csv\", header=True, inferSchema=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "22895bb2",
      "metadata": {
        "id": "22895bb2"
      },
      "outputs": [],
      "source": [
        "# Define the feature columns\n",
        "feature_columns = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "571fb00d",
      "metadata": {
        "id": "571fb00d"
      },
      "outputs": [],
      "source": [
        "# Create a StringIndexer to encode the \"species\" column\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "data = indexer.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f4f058ff",
      "metadata": {
        "id": "f4f058ff"
      },
      "outputs": [],
      "source": [
        "# Create a vector assembler to combine feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0be4b1c6",
      "metadata": {
        "id": "0be4b1c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm = LinearSVC(maxIter=100, labelCol=\"label\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b2b9e889",
      "metadata": {
        "scrolled": true,
        "id": "b2b9e889"
      },
      "outputs": [],
      "source": [
        "# Create an OvR classifier\n",
        "ovr_classifier = OneVsRest(classifier=svm, labelCol=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e03ac930",
      "metadata": {
        "id": "e03ac930"
      },
      "outputs": [],
      "source": [
        "# Train the OvR model\n",
        "ovr_model = ovr_classifier.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "37d4868e",
      "metadata": {
        "id": "37d4868e"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = ovr_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d27446d6",
      "metadata": {
        "id": "d27446d6"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9e78dd16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e78dd16",
        "outputId": "d0e9bcdd-c68a-4d20-f402-c9678990dfa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.10%\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy of the model\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e4e4e767",
      "metadata": {
        "id": "e4e4e767"
      },
      "outputs": [],
      "source": [
        "# Convert the predictions and labels to RDD for MulticlassMetrics\n",
        "prediction_and_label = predictions.select(\"prediction\", \"label\").rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a7c5859f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7c5859f",
        "outputId": "9630fbfa-99b7-4f5c-87d3-9b3cf4fcd549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate MulticlassMetrics\n",
        "metrics = MulticlassMetrics(prediction_and_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3e3f57a8",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3f57a8",
        "outputId": "b24a3e8e-84b5-4d7c-fec0-e86251034e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[13.  0.  0.]\n",
            " [ 0.  6.  1.]\n",
            " [ 0.  1.  8.]]\n"
          ]
        }
      ],
      "source": [
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusionMatrix().toArray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5140b721",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5140b721",
        "outputId": "9547a51a-db9b-455a-e731-ae76064d5a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for Setosa class: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Get the recall for the \"Setosa\" class (class index 0)\n",
        "setosa_recall = metrics.recall(0)\n",
        "\n",
        "# Print the recall for the \"Setosa\" class\n",
        "print(f\"Recall for Setosa class: {setosa_recall:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b089c3e8",
      "metadata": {
        "id": "b089c3e8"
      },
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}