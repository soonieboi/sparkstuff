{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aef7a115",
      "metadata": {
        "id": "aef7a115"
      },
      "source": [
        "### 1. Set up spark context and SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Install OpenJDK 21 (if not already done in a previous cell)\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq openjdk-21-jdk-headless\n",
        "\n",
        "# 2. Verify where it landed (if needed)\n",
        "!ls /usr/lib/jvm | grep 21\n",
        "\n",
        "# 3. Point to JDK 21\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "# 4. Install PySpark via pip (make sure this happens AFTER setting JAVA_HOME)\n",
        "!pip install pyspark --quiet\n",
        "\n",
        "# 5. Import and start Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .master(\"local[*]\")\n",
        "      .appName(\"PySpark-RandomForestClassifier_Iris\")\n",
        "      .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l665K1cZia94",
        "outputId": "088dc764-9957-4ce4-9775-9f1a9f27f255"
      },
      "id": "l665K1cZia94",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package openjdk-21-jre-headless:amd64.\n",
            "(Reading database ... 126109 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-21-jre-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-21-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-21-jdk-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jwebserver to provide /usr/bin/jwebserver (jwebserver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "java-1.21.0-openjdk-amd64\n",
            "java-21-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google drive"
      ],
      "metadata": {
        "id": "kMfg1qikiiYB"
      },
      "id": "kMfg1qikiiYB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEWj5jjWilmZ",
        "outputId": "895cedce-5f87-4e01-c43f-c78d1f0db206"
      },
      "id": "nEWj5jjWilmZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37fee105",
      "metadata": {
        "id": "37fee105"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08b6bc96",
      "metadata": {
        "id": "08b6bc96"
      },
      "source": [
        "### 2. Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "973ed743",
      "metadata": {
        "id": "973ed743"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset (assuming you have it in a CSV format)\n",
        "iris_data = spark.read.csv(\"/content/iris-data.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "840d1e43",
      "metadata": {
        "id": "840d1e43"
      },
      "outputs": [],
      "source": [
        "# Assuming the target variable is \"class\" and other columns are features\n",
        "feature_cols = iris_data.columns[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "83b0c85d",
      "metadata": {
        "id": "83b0c85d"
      },
      "outputs": [],
      "source": [
        "# Convert string labels into numerical labels\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "iris_data = indexer.fit(iris_data).transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a9a14fe6",
      "metadata": {
        "id": "a9a14fe6"
      },
      "outputs": [],
      "source": [
        "# Create a feature vector by assembling the feature columns\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "data = assembler.transform(iris_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dca96493",
      "metadata": {
        "id": "dca96493"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "(training_data, testing_data) = data.randomSplit([0.8, 0.2], seed=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "690a235e",
      "metadata": {
        "id": "690a235e"
      },
      "outputs": [],
      "source": [
        "# Customized parameters\n",
        "num_trees = 10\n",
        "max_depth = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dd505adc",
      "metadata": {
        "id": "dd505adc"
      },
      "outputs": [],
      "source": [
        "# Create and train a RandomForestClassifier with customized parameters\n",
        "rf = RandomForestClassifier(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    numTrees=num_trees,\n",
        "    maxDepth=max_depth\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5da887dc",
      "metadata": {
        "id": "5da887dc"
      },
      "outputs": [],
      "source": [
        "model = rf.fit(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "47271c59",
      "metadata": {
        "id": "47271c59"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3facc32f",
      "metadata": {
        "id": "3facc32f"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "700c793d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700c793d",
        "outputId": "7da390ce-3785-4ca1-c0c3-b64a35976877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fda6a0d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fda6a0d1",
        "outputId": "47e29eda-11fe-4d47-fe04-ba257a664484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:  (4,[0,1,2,3],[0.14855900919958878,0.017477117982863583,0.4161820723775073,0.4177818004400404])\n"
          ]
        }
      ],
      "source": [
        "# Show the feature importances\n",
        "print(\"Feature Importances: \", model.featureImportances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "349da959",
      "metadata": {
        "id": "349da959"
      },
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}