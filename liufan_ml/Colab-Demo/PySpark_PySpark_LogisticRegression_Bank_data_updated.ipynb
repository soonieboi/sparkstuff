{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCIGWnMMtEuv",
        "outputId": "7f2dce72-c0ca-4947-dbf3-7b0f8bfe7cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package openjdk-21-jre-headless:amd64.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-21-jre-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-21-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-21-jdk-headless_21.0.7+6~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "Setting up openjdk-21-jre-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-21-jdk-headless:amd64 (21.0.7+6~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jwebserver to provide /usr/bin/jwebserver (jwebserver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "java-1.21.0-openjdk-amd64\n",
            "java-21-openjdk-amd64\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 1. Install OpenJDK 21 (if not already done in a previous cell)\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq openjdk-21-jdk-headless\n",
        "\n",
        "# 2. Verify where it landed (if needed)\n",
        "!ls /usr/lib/jvm | grep 21\n",
        "\n",
        "# 3. Point to JDK 21\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "# 4. Install PySpark via pip (make sure this happens AFTER setting JAVA_HOME)\n",
        "!pip install pyspark --quiet\n",
        "\n",
        "# 5. Import and start Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "      .master(\"local[*]\")\n",
        "      .appName(\"PySpark-LogisticRegression_Bank\")\n",
        "      .getOrCreate()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3cMSV9GteWJ",
        "outputId": "1301766c-ef16-45b3-f0df-9ac5b126fa3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Load Data set"
      ],
      "metadata": {
        "id": "uDP0vLJFzhEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data set into drive-> MyDrive->Colab Notebooks\n",
        "df = spark.read.format('com.databricks.spark.csv').\\\n",
        "                               options(header='true', \\\n",
        "                               inferschema='true').load(\"/content/bank.csv\",header=True);"
      ],
      "metadata": {
        "id": "4_5or9amzj_b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('day','month','poutcome').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_s7HSu0zr3N",
        "outputId": "ecca0b70-2c06-4ab6-df99-241a2e9f672b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
            "|age|        job|marital|education|default|balance|housing|loan| contact|duration|campaign|pdays|previous|  y|\n",
            "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
            "| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular|      79|       1|   -1|       0|  0|\n",
            "| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular|     220|       1|  339|       4|  0|\n",
            "| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular|     185|       1|  330|       1|  0|\n",
            "| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|     199|       4|   -1|       0|  0|\n",
            "| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|     226|       1|   -1|       0|  0|\n",
            "+---+-----------+-------+---------+-------+-------+-------+----+--------+--------+--------+-----+--------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9assivwxzs35",
        "outputId": "a89ae382-7578-45b8-90f1-22e0b8509bd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- y: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dummy(df,categoricalCols,continuousCols,labelCol):\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    from pyspark.sql.functions import col\n",
        "\n",
        "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
        "                 for c in categoricalCols ]\n",
        "\n",
        "    # default setting: dropLast=True\n",
        "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
        "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
        "                 for indexer in indexers ]\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
        "                                + continuousCols, outputCol=\"features\")\n",
        "\n",
        "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "\n",
        "    model=pipeline.fit(df)\n",
        "    data = model.transform(df)\n",
        "\n",
        "    data = data.withColumn('label',col(labelCol))\n",
        "\n",
        "    return data.select('features','label')"
      ],
      "metadata": {
        "id": "fCKEocrG2dA5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors # !!!!caution: not from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "y4OdS606z3HR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Deal with categorical data and convert the data to dense vector"
      ],
      "metadata": {
        "id": "TsIjRUT0z7Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "catcols = ['job','marital','education','default',\n",
        "           'housing','loan','contact','poutcome']\n",
        "\n",
        "num_cols = ['balance', 'duration','campaign','pdays','previous',]\n",
        "labelCol = 'y'\n",
        "\n",
        "data = get_dummy(df,catcols,num_cols,labelCol)\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWOgxT40Aek",
        "outputId": "61f0e18c-66dc-4900-f33b-e4d3c6867c53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(29,[8,11,15,16,1...|    0|\n",
            "|(29,[4,11,13,16,1...|    0|\n",
            "|(29,[0,12,14,16,1...|    0|\n",
            "|(29,[0,11,14,16,1...|    0|\n",
            "|(29,[1,11,13,16,1...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Deal with categorical label and variable"
      ],
      "metadata": {
        "id": "O_WrSgn00C4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# Index labels, adding metadata to the label column\n",
        "labelIndexer = StringIndexer(inputCol='label',\n",
        "                             outputCol='indexedLabel').fit(data)\n",
        "labelIndexer.transform(data).show(5, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXNF_fVv2xof",
        "outputId": "d4a70681-2834-4f83-ca5b-a267ea7e94bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------------+\n",
            "|            features|label|indexedLabel|\n",
            "+--------------------+-----+------------+\n",
            "|(29,[8,11,15,16,1...|    0|         0.0|\n",
            "|(29,[4,11,13,16,1...|    0|         0.0|\n",
            "|(29,[0,12,14,16,1...|    0|         0.0|\n",
            "|(29,[0,11,14,16,1...|    0|         0.0|\n",
            "|(29,[1,11,13,16,1...|    0|         0.0|\n",
            "+--------------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorIndexer\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =VectorIndexer(inputCol=\"features\", \\\n",
        "                                  outputCol=\"indexedFeatures\", \\\n",
        "                                  maxCategories=4).fit(data)\n",
        "featureIndexer.transform(data).show(5, True)"
      ],
      "metadata": {
        "id": "O2H1v9uW0Ghu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c795d08a-2483-4d14-923c-2eedb6a79b6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------------+\n",
            "|            features|label|     indexedFeatures|\n",
            "+--------------------+-----+--------------------+\n",
            "|(29,[8,11,15,16,1...|    0|(29,[8,11,15,16,1...|\n",
            "|(29,[4,11,13,16,1...|    0|(29,[4,11,13,16,1...|\n",
            "|(29,[0,12,14,16,1...|    0|(29,[0,12,14,16,1...|\n",
            "|(29,[0,11,14,16,1...|    0|(29,[0,11,14,16,1...|\n",
            "|(29,[1,11,13,16,1...|    0|(29,[1,11,13,16,1...|\n",
            "+--------------------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets (40% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
        "\n",
        "trainingData.show(5,False)\n",
        "testData.show(5,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TUS_JSU0Pei",
        "outputId": "88d59db7-e182-4412-8f14-ae4f0ffe1532"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------+-----+\n",
            "|features                                                                                        |label|\n",
            "+------------------------------------------------------------------------------------------------+-----+\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-588.0,81.0,4.0,-1.0])|0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-105.0,60.0,2.0,-1.0])|0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,-1.0]) |0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,-1.0])|0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,-1.0])|0    |\n",
            "+------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------------------------------------------------------------------------------------+-----+\n",
            "|features                                                                                          |label|\n",
            "+--------------------------------------------------------------------------------------------------+-----+\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,-1.0])  |0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,644.0,54.0,2.0,-1.0])   |0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1007.0,240.0,2.0,-1.0]) |0    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1623.0,1081.0,2.0,-1.0])|1    |\n",
            "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3180.0,384.0,1.0,-1.0]) |0    |\n",
            "+--------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Fit logistic Regression Model"
      ],
      "metadata": {
        "id": "S94wngYa0gwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "logr = LogisticRegression(featuresCol='indexedFeatures', labelCol='indexedLabel')"
      ],
      "metadata": {
        "id": "82sOa47u0kBN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Create Pipeline"
      ],
      "metadata": {
        "id": "BifDqxGE0nlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "# Chain indexers and tree in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, logr,labelConverter])\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "wmMlVCIt0p88"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Make prediction"
      ],
      "metadata": {
        "id": "5jx7glPz3VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "# Select example rows to display.\n",
        "predictions.select(\"features\",\"label\",\"predictedLabel\").show(5)\n",
        "predictions.select('label').distinct().collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gwnlnlN3W4j",
        "outputId": "b4f4e3d1-cb5e-4112-fdb1-6c1d4fb8b67b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+--------------+\n",
            "|            features|label|predictedLabel|\n",
            "+--------------------+-----+--------------+\n",
            "|(29,[0,11,13,16,1...|    0|             0|\n",
            "|(29,[0,11,13,16,1...|    0|             0|\n",
            "|(29,[0,11,13,16,1...|    0|             0|\n",
            "|(29,[0,11,13,16,1...|    1|             1|\n",
            "|(29,[0,11,13,16,1...|    0|             0|\n",
            "+--------------------+-----+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=1), Row(label=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Evaluation\n"
      ],
      "metadata": {
        "id": "M7E_Tebj3bTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxOIw0Rc3i1G",
        "outputId": "38fb158b-7daa-414b-cb05-3e4bad1434e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.107955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrModel = model.stages[2]\n",
        "trainingSummary = lrModel.summary\n",
        "# Obtain the objective per iteration\n",
        "# objectiveHistory = trainingSummary.objectiveHistory\n",
        "# print(\"objectiveHistory:\")\n",
        "# for objective in objectiveHistory:\n",
        "#     print(objective)\n",
        "\n",
        "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
        "trainingSummary.roc.show(5)\n",
        "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
        "\n",
        "# Set the model threshold to maximize F-Measure\n",
        "fMeasure = trainingSummary.fMeasureByThreshold\n",
        "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head(5)\n",
        "# bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
        "#     .select('threshold').head()['threshold']\n",
        "# lr.setThreshold(bestThreshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Ae-3f-3NNC",
        "outputId": "02098899-be9e-4a45-da8f-8efac29f2d1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|                 FPR|                 TPR|\n",
            "+--------------------+--------------------+\n",
            "|                 0.0|                 0.0|\n",
            "|                 0.0|0.006349206349206349|\n",
            "|4.088307440719542E-4|0.009523809523809525|\n",
            "|4.088307440719542E-4|0.015873015873015872|\n",
            "|8.176614881439084E-4| 0.01904761904761905|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "areaUnderROC: 0.9001408194785139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "cLdwbeFX0_uq"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}